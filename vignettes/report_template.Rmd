---
title: "Getting Started with HarborMetrics"
output:
  rmarkdown::html_vignette:
    keep_md: true
vignette: >
  %\VignetteIndexEntry{Getting Started with HarborMetrics}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Introduction

Efficient port operations are vital to global trade, yet weather events and operational variability can lead to costly delays. **HarborMetrics** provides an end-to-end solution for analyzing and forecasting daily port efficiency metrics, such as ship waiting time and cargo throughput. By seamlessly integrating weather features with historical operations data, users can build prediction models, quantify weather impacts, and simulate "what-if" scenarios to inform decision-making.

# Workflow

```r
# Install and load the package
# remotes::install_github("yourorg/HarborMetrics")
library(HarborMetrics)

# Load and preprocess data
data_raw   <- load_port_data("NewYork_dailydata.csv")
data_clean <- clean_port_data(data_raw) %>%
  add_weather_features()

# Fit a model for ship waiting time
model <- fit_efficiency_model(data_clean, target = "ship_wait_time")

# Explore operational trends and correlations
plot_operational_trend(data_clean)
plot_correlation_heatmap(data_clean)

# Simulate a storm scenario
simulate_scenario(model, new_weather = list(max_wind_speed = 25, precipitation = 0.5))

# Validate the model and generate a report
validate_model(model, test_data = data_clean)
generate_report(data_clean, "port_report.html")
```

# Advantages & Learned Points

- **End-to-End Pipeline**: Simplifies the entire workflow from raw CSV import (`load_port_data()`) to interactive scenario simulation (`simulate_scenario()`).
- **Tidy Data Principles**: Employs **dplyr** and **tidyr** with the `%>%` operator for readable, reproducible data transformations.
- **Robust Date Handling**: Leverages **lubridate** for parsing and manipulating date-time fields, essential for time series analysis.
- **Time Series Forecasting**: Integrates the **forecast** package to provide ARIMA and exponential smoothing models, supporting multiple modeling approaches.
- **Constraint-Based Optimization**: Implements linear programming in `optimize_schedule()` to allocate cargo under operational constraints.
- **Interactive Visualizations**: Combines **ggplot2** for static plots and **plotly** for dynamic charts, enabling users to explore weather-operations relationships.
- **Reproducible Reporting**: Automates report generation via **rmarkdown**, ensuring consistent outputs in HTML or PDF formats.
- **Unit Testing**: Utilizes **testthat** to enforce model accuracy (e.g., RMSE < 1 hour) and functional reliability, enhancing code quality.
- **Modular Package Design**: Uses **usethis** to scaffold the project structure, manage dependencies, and facilitate collaborative development.
- **Extensibility**: Offers clear function interfaces for customizing models, features, and evaluation metrics, making future extensions straightforward.
- **Performance Benchmarking**: Includes tools to measure function efficiency across varying data sizes and model types.
- **Standardized Documentation**: Adopts **roxygen2** for inline documentation and **pkgdown** to generate a dedicated website for help files.
- **Cross-Platform Compatibility**: Supports Windows, macOS, and Linux environments, suitable for local or cloud-based deployment.
- **Scenario Analysis**: Enables comparison of multiple hypothetical weather scenarios through `simulate_scenario()` for risk assessment and contingency planning.

> This vignette demonstrates core course concepts, from modular package development, advanced data wrangling, and time series modeling, to optimization, interactive visualization, and automated reporting, showcasing the design philosophy and features of HarborMetrics.
